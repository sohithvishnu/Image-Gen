


import torch
print(torch.backends.mps.is_available())


import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
from PIL import Image
import os

# Check if MPS is available
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

# Custom Dataset Class for Loading Images
class ImageDataset(Dataset):
    def __init__(self, dataset_path, image_size=(128, 128)):
        self.dataset_path = dataset_path
        self.image_size = image_size
        self.images = []
        
        # Load all images
        for filename in sorted(os.listdir(dataset_path)):
            if filename.endswith(".jpg") or filename.endswith(".png"):
                img = Image.open(os.path.join(dataset_path, filename)).resize(image_size)
                img = np.array(img).astype(np.float32) / 255.0
                self.images.append(img)
        
        self.images = torch.tensor(np.transpose(self.images, (0, 3, 1, 2)))  # N, C, H, W

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        return self.images[idx]

# Load the dataset
dataset_path = "dataset/"  # Adjust this to your dataset path
dataset = ImageDataset(dataset_path)
data_loader = DataLoader(dataset, batch_size=2, shuffle=True)

# Define Autoencoder Model
class Autoencoder(nn.Module):
    def __init__(self, latent_dim=64):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(),
        )
        self.fc1 = nn.Linear(128 * 16 * 16, latent_dim)  # 16x16 comes from downsampling

        self.fc2 = nn.Linear(latent_dim, 128 * 16 * 16)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),
            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = x.view(x.size(0), -1)  # Flatten
        x = self.fc1(x)  # Latent space
        x = self.fc2(x)  # Expand back
        x = x.view(x.size(0), 128, 16, 16)  # Reshape for decoder
        return self.decoder(x)

# Initialize the model and move it to the device (MPS or CPU)
model = Autoencoder().to(device)



# Define the optimizer and loss function
optimizer = optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.MSELoss()

# Training loop (overfitting to the data)
num_epochs = 1000

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images in data_loader:
        images = images.to(device)  # Move images to MPS/CPU

        # Zero the gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(images)

        # Compute loss
        loss = loss_fn(outputs, images)

        # Backward pass and optimization
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    # Print the loss every 100 epochs
    if (epoch + 1) % 100 == 0:
        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(data_loader):.4f}")




# Function to generate an image
def generate_image(model, idx):
    model.eval()
    with torch.no_grad():
        img = dataset[idx].unsqueeze(0).to(device)  # Get image and move to device
        output = model(img)
        output = output.squeeze(0).cpu().numpy().transpose(1, 2, 0) * 255
        output = np.clip(output, 0, 255).astype(np.uint8)
        Image.fromarray(output).show()

generate_image(model, 1)  # Test with the first image in the dataset



# Save the trained model
torch.save(model.state_dict(), 'autoencoder_model.pth')
print("Model saved successfully!")


# Load the model (after training or in a new session)
model = Autoencoder().to(device)
model.load_state_dict(torch.load('autoencoder_model.pth'))
model.eval()  # Set the model to evaluation mode
print("Model loaded successfully!")


# Function to generate an image from a saved model
def generate_image(model, idx):
    with torch.no_grad():
        img = dataset[idx].unsqueeze(0).to(device)  # Get the image and move it to device
        output = model(img)
        output = output.squeeze(0).cpu().numpy().transpose(1, 2, 0) * 192
        output = np.clip(output, 0, 255).astype(np.uint8)
        Image.fromarray(output).show()

# Generate an image using the loaded model
generate_image(model, 0)  # Generate an image from the first example in the dataset






import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import torchvision


class Generator(nn.Module):
    def __init__(self, z_dim, label_dim):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + label_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 28*28*1),
            nn.Tanh()
        )

    def forward(self, z, labels):
        # Combine random noise and labels
        x = torch.cat([z, labels], dim=1)
        return self.fc(x).view(-1, 1, 28, 28)

class Discriminator(nn.Module):
    def __init__(self, label_dim):
        super(Discriminator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(28*28 + label_dim, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, x, labels):
        # Flatten image
        x = x.view(x.size(0), -1)
        # Combine image and label
        x = torch.cat([x, labels], dim=1)
        return self.fc(x)



# Define a transformation for the MNIST dataset
transform = transforms.Compose([
    transforms.Resize(28),        # Resize images to 28x28
    transforms.ToTensor(),        # Convert images to tensors
    transforms.Normalize((0.5,), (0.5,))  # Normalize images to [-1, 1]
])

# Download and load the MNIST dataset
dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)

# DataLoader for batching the dataset
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)



# Initialize models
z_dim = 100  # Latent vector size
label_dim = 10  # Number of classes in MNIST (0-9)
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
print(device)

generator = Generator(z_dim, label_dim).to(device)
discriminator = Discriminator(label_dim).to(device)

# Optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# Loss function
criterion = nn.BCELoss()

# Function to generate labels as one-hot vectors
def one_hot(labels, label_dim, device='cpu'):
    return torch.eye(label_dim, device=device)[labels]



# Training loop
epochs = 20 # Number of epochs

for epoch in range(epochs):
    for i, (real_images, labels) in enumerate(dataloader):
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        labels_onehot = one_hot(labels, label_dim, device)

        # Create labels for real and fake images
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # Train Discriminator
        optimizer_D.zero_grad()
        
        # Train with real images
        outputs = discriminator(real_images, labels_onehot)
        d_loss_real = criterion(outputs, real_labels)
        
        # Generate fake images
        z = torch.randn(batch_size, z_dim).to(device)
        fake_images = generator(z, labels_onehot)
        outputs = discriminator(fake_images.detach(), labels_onehot)  # Detach to not update generator
        d_loss_fake = criterion(outputs, fake_labels)
        
        # Total discriminator loss
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        outputs = discriminator(fake_images, labels_onehot)
        g_loss = criterion(outputs, real_labels)
        g_loss.backward()
        optimizer_G.step()

    print(f'Epoch [{epoch+1}/{epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}')

    # Save generated images for visualization
    if (epoch + 1) % 5 == 0:
        with torch.no_grad():
            z = torch.randn(16, z_dim).to(device)
            labels_onehot = one_hot(torch.randint(0, 10, (16,)).to(device), label_dim, device=device)
            generated_images = generator(z, labels_onehot)
            generated_images = generated_images.cpu().data
            grid = torchvision.utils.make_grid(generated_images, nrow=4, normalize=True)
            plt.imshow(grid.permute(1, 2, 0))
            plt.show()



# Save the models after training
torch.save(generator.state_dict(), 'generator.pth')
torch.save(discriminator.state_dict(), 'discriminator.pth')



import torch
import torchvision
import matplotlib.pyplot as plt

# Function to generate an image using the trained generator
def generate_image(generator, label, z_dim=100, label_dim=10, device='cpu'):
    # Random noise vector
    z = torch.randn(1, z_dim).to(device)  # Latent vector (random noise)

    # One-hot encoding of the label
    label_onehot = torch.eye(label_dim)[label].unsqueeze(0).to(device)  # One-hot encoded label

    # Generate image using the generator
    with torch.no_grad():  # No need to calculate gradients for this
        generated_image = generator(z, label_onehot)  # Feed noise and label to generator

    # Reshape the generated image to be in the correct format for visualization
    generated_image = generated_image.squeeze(0).cpu()  # Remove batch dimension and move to CPU

    # Display the generated image
    plt.imshow(generated_image.squeeze(), cmap='gray')
    plt.axis('off')  # Hide axes
    plt.show()

# Example: Generate an image for label 7 (digit '7')
label = 7
generate_image(generator, label, z_dim=100, label_dim=10, device='mps')






import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import torchvision

# Overfitting Generator
class Generator(nn.Module):
    def __init__(self, z_dim, label_dim):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + label_dim, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 2048),
            nn.ReLU(True),
            nn.Linear(2048, 28*28),
            nn.Tanh()
        )

    def forward(self, z, labels):
        x = torch.cat([z, labels], dim=1)
        return self.fc(x).view(-1, 1, 28, 28)

# Overfitting Discriminator
class Discriminator(nn.Module):
    def __init__(self, label_dim):
        super(Discriminator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(28*28 + label_dim, 2048),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(2048, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 1),
            nn.Sigmoid()
        )

    def forward(self, x, labels):
        x = x.view(x.size(0), -1)
        x = torch.cat([x, labels], dim=1)
        return self.fc(x)

# Set device
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

# Overfit to small dataset
transform = transforms.Compose([
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Load only a small part of MNIST (overfitting target)
dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
small_dataset, _ = torch.utils.data.random_split(dataset, [100, len(dataset) - 100])  # Overfit to 100 samples
dataloader = DataLoader(small_dataset, batch_size=16, shuffle=True)

# Latent vector size (smaller z_dim for less randomness)
z_dim = 10
label_dim = 10
epochs = 500  # Train for a long time

# Initialize models
generator = Generator(z_dim, label_dim).to(device)
discriminator = Discriminator(label_dim).to(device)

# Optimizers (higher learning rate to memorize quickly)
optimizer_G = optim.Adam(generator.parameters(), lr=0.01, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.01, betas=(0.5, 0.999))

# Loss function
criterion = nn.BCELoss()

# One-hot encoding function
def one_hot(labels, label_dim, device='cpu'):
    return torch.eye(label_dim, device=device)[labels]

# Training loop for overfitting
for epoch in range(epochs):
    for i, (real_images, labels) in enumerate(dataloader):
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        labels_onehot = one_hot(labels, label_dim, device)

        # Labels
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # Train Discriminator
        optimizer_D.zero_grad()
        outputs = discriminator(real_images, labels_onehot)
        d_loss_real = criterion(outputs, real_labels)

        z = torch.randn(batch_size, z_dim).to(device)
        fake_images = generator(z, labels_onehot)
        outputs = discriminator(fake_images.detach(), labels_onehot)
        d_loss_fake = criterion(outputs, fake_labels)

        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        outputs = discriminator(fake_images, labels_onehot)
        g_loss = criterion(outputs, real_labels)
        g_loss.backward()
        optimizer_G.step()

    if epoch % 50 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')
        with torch.no_grad():
            z = torch.randn(16, z_dim).to(device)
            labels_onehot = one_hot(torch.randint(0, 10, (16,)).to(device), label_dim, device=device)
            generated_images = generator(z, labels_onehot)
            generated_images = generated_images.cpu().data
            grid = torchvision.utils.make_grid(generated_images, nrow=4, normalize=True)
            plt.imshow(grid.permute(1, 2, 0))
            plt.show()




