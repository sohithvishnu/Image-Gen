{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "adaqlwCzUVp4"
      },
      "outputs": [],
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n6w4QoDfKXQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafe519a-17a6-42b3-ff7e-0104031854a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 480kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.72MB/s]\n"
          ]
        }
      ],
      "source": [
        "bs = 100\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1MbrOKuuKZkT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConditionalGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, img_channels=1):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim + num_classes, 128, kernel_size=7, stride=1, padding=0),  # 7x7\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 14x14\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, img_channels, kernel_size=4, stride=2, padding=1),  # 28x28\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        label_embedding = self.label_emb(labels)\n",
        "        x = torch.cat([z, label_embedding], dim=1)\n",
        "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class ConditionalDiscriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_channels=1):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(img_channels + num_classes, 64, kernel_size=4, stride=2, padding=1),  # 14x14\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 7x7\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 7 * 7, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        label_embedding = self.label_emb(labels)  # [B, num_classes]\n",
        "        label_map = label_embedding.view(labels.size(0), -1, 1, 1)  # ✅ Correct!\n",
        "        label_map = label_map.expand(-1, -1, x.size(2), x.size(3))  # [B, num_classes, 28, 28]\n",
        "        x = torch.cat([x, label_map], dim=1)  # [B, 1+num_classes, 28, 28]\n",
        "        return self.net(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PBV41-TrKaPS"
      },
      "outputs": [],
      "source": [
        "z_dim = 100\n",
        "num_classes = 10\n",
        "\n",
        "G = ConditionalGenerator(z_dim=z_dim, num_classes=num_classes).to(device)\n",
        "D = ConditionalDiscriminator(num_classes=num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zO3ROanKlf3",
        "outputId": "367e0579-d841-458d-cdf3-dd6a2d963bb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConditionalGenerator(\n",
              "  (label_emb): Embedding(10, 10)\n",
              "  (net): Sequential(\n",
              "    (0): ConvTranspose2d(110, 128, kernel_size=(7, 7), stride=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (7): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm2SsDDJKmdJ",
        "outputId": "b67e11f3-7a0c-4040-9c03-9eebe4fd409b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConditionalDiscriminator(\n",
              "  (label_emb): Embedding(10, 10)\n",
              "  (net): Sequential(\n",
              "    (0): Conv2d(11, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Flatten(start_dim=1, end_dim=-1)\n",
              "    (6): Linear(in_features=6272, out_features=1, bias=True)\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hIPWE7EIKfsS"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "lr = 0.0002\n",
        "\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Mycy__aSKoIo"
      },
      "outputs": [],
      "source": [
        "def D_train(real_images, real_labels):\n",
        "    D.zero_grad()\n",
        "\n",
        "    bs = real_images.size(0)\n",
        "\n",
        "    # === Train on real images ===\n",
        "    y_real = torch.ones(bs, 1).to(device)\n",
        "    real_images = real_images.to(device)\n",
        "    real_labels = real_labels.to(device)\n",
        "\n",
        "    D_output_real = D(real_images, real_labels)\n",
        "    D_real_loss = criterion(D_output_real, y_real)\n",
        "\n",
        "    # === Train on fake images ===\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "    fake_images = G(z, real_labels)  # condition on same labels\n",
        "\n",
        "    y_fake = torch.zeros(bs, 1).to(device)\n",
        "    D_output_fake = D(fake_images.detach(), real_labels)\n",
        "    D_fake_loss = criterion(D_output_fake, y_fake)\n",
        "\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return D_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dj1pc-O0Kpyh"
      },
      "outputs": [],
      "source": [
        "def G_train(labels):\n",
        "    G.zero_grad()\n",
        "\n",
        "    bs = labels.size(0)\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    y_real = torch.ones(bs, 1).to(device)  # generator wants D to think fake is real\n",
        "    fake_images = G(z, labels)\n",
        "    D_output = D(fake_images, labels)\n",
        "\n",
        "    G_loss = criterion(D_output, y_real)\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "p8b6pg94KrfD",
        "outputId": "dc59edcf-7f07-473b-f66b-8cceedcbb3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/20]: loss_d: 1.324, loss_g: 0.802\n",
            "Saved samples for epoch 1 to /content/samples/generated_epoch_1.png\n",
            "[2/20]: loss_d: 1.353, loss_g: 0.773\n",
            "Saved samples for epoch 2 to /content/samples/generated_epoch_2.png\n",
            "[3/20]: loss_d: 1.363, loss_g: 0.764\n",
            "Saved samples for epoch 3 to /content/samples/generated_epoch_3.png\n",
            "[4/20]: loss_d: 1.366, loss_g: 0.757\n",
            "Saved samples for epoch 4 to /content/samples/generated_epoch_4.png\n",
            "[5/20]: loss_d: 1.363, loss_g: 0.755\n",
            "Saved samples for epoch 5 to /content/samples/generated_epoch_5.png\n",
            "[6/20]: loss_d: 1.362, loss_g: 0.760\n",
            "Saved samples for epoch 6 to /content/samples/generated_epoch_6.png\n",
            "[7/20]: loss_d: 1.357, loss_g: 0.763\n",
            "Saved samples for epoch 7 to /content/samples/generated_epoch_7.png\n",
            "[8/20]: loss_d: 1.352, loss_g: 0.765\n",
            "Saved samples for epoch 8 to /content/samples/generated_epoch_8.png\n",
            "[9/20]: loss_d: 1.344, loss_g: 0.772\n",
            "Saved samples for epoch 9 to /content/samples/generated_epoch_9.png\n",
            "[10/20]: loss_d: 1.339, loss_g: 0.778\n",
            "Saved samples for epoch 10 to /content/samples/generated_epoch_10.png\n",
            "[11/20]: loss_d: 1.332, loss_g: 0.785\n",
            "Saved samples for epoch 11 to /content/samples/generated_epoch_11.png\n",
            "[12/20]: loss_d: 1.323, loss_g: 0.793\n",
            "Saved samples for epoch 12 to /content/samples/generated_epoch_12.png\n",
            "[13/20]: loss_d: 1.314, loss_g: 0.806\n",
            "Saved samples for epoch 13 to /content/samples/generated_epoch_13.png\n",
            "[14/20]: loss_d: 1.306, loss_g: 0.811\n",
            "Saved samples for epoch 14 to /content/samples/generated_epoch_14.png\n",
            "[15/20]: loss_d: 1.293, loss_g: 0.825\n",
            "Saved samples for epoch 15 to /content/samples/generated_epoch_15.png\n",
            "[16/20]: loss_d: 1.285, loss_g: 0.832\n",
            "Saved samples for epoch 16 to /content/samples/generated_epoch_16.png\n",
            "[17/20]: loss_d: 1.277, loss_g: 0.841\n",
            "Saved samples for epoch 17 to /content/samples/generated_epoch_17.png\n",
            "[18/20]: loss_d: 1.268, loss_g: 0.853\n",
            "Saved samples for epoch 18 to /content/samples/generated_epoch_18.png\n",
            "[19/20]: loss_d: 1.259, loss_g: 0.867\n",
            "Saved samples for epoch 19 to /content/samples/generated_epoch_19.png\n",
            "[20/20]: loss_d: 1.253, loss_g: 0.875\n",
            "Saved samples for epoch 20 to /content/samples/generated_epoch_20.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_253c93e1-ff1a-4a1a-b45b-f5d2788ad0ca\", \"generated_digits.zip\", 108139)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "save_dir = \"/content/samples\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "n_epoch = 20\n",
        "bs = 100\n",
        "sample_size = 10  # one digit from 0 to 9\n",
        "\n",
        "for epoch in range(1, n_epoch + 1):\n",
        "    G.train()\n",
        "    D.train()\n",
        "    D_losses, G_losses = [], []\n",
        "\n",
        "    for batch_idx, (real_images, real_labels) in enumerate(train_loader):\n",
        "        d_loss = D_train(real_images, real_labels)\n",
        "        g_loss = G_train(real_labels)\n",
        "        D_losses.append(d_loss)\n",
        "        G_losses.append(g_loss)\n",
        "\n",
        "    avg_d_loss = torch.mean(torch.FloatTensor(D_losses))\n",
        "    avg_g_loss = torch.mean(torch.FloatTensor(G_losses))\n",
        "    print(f\"[{epoch}/{n_epoch}]: loss_d: {avg_d_loss:.3f}, loss_g: {avg_g_loss:.3f}\")\n",
        "\n",
        "    # Save 1 sample per digit after each epoch\n",
        "    G.eval()\n",
        "    with torch.no_grad():\n",
        "        test_labels = torch.arange(0, 10).long().to(device)\n",
        "        test_z = torch.randn(10, z_dim).to(device)\n",
        "        generated = G(test_z, test_labels)\n",
        "\n",
        "        save_path = os.path.join(save_dir, f'generated_epoch_{epoch}.png')\n",
        "        save_image(generated, save_path, nrow=10, normalize=True)\n",
        "        print(f\"Saved samples for epoch {epoch} to {save_path}\")\n",
        "\n",
        "# Zip the folder of images\n",
        "zip_path = \"/content/generated_digits\"\n",
        "shutil.make_archive(zip_path, 'zip', save_dir)\n",
        "\n",
        "# Download to your computer\n",
        "files.download(zip_path + \".zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "G58P4D3-Nd1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7a7661fa-41dc-4fc4-ae1a-cb5cbadbcd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved digit 0 to /content/digits/digit_0.png\n",
            "Saved digit 1 to /content/digits/digit_1.png\n",
            "Saved digit 2 to /content/digits/digit_2.png\n",
            "Saved digit 3 to /content/digits/digit_3.png\n",
            "Saved digit 4 to /content/digits/digit_4.png\n",
            "Saved digit 5 to /content/digits/digit_5.png\n",
            "Saved digit 6 to /content/digits/digit_6.png\n",
            "Saved digit 7 to /content/digits/digit_7.png\n",
            "Saved digit 8 to /content/digits/digit_8.png\n",
            "Saved digit 9 to /content/digits/digit_9.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aca0bd53-8b20-4ed3-a0d2-1bf921e9ac53\", \"digit_images.zip\", 7732)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Folder to save individual digit images\n",
        "digit_save_dir = \"/content/digits\"\n",
        "os.makedirs(digit_save_dir, exist_ok=True)\n",
        "\n",
        "# Generate one image for each digit (0–9)\n",
        "G.eval()\n",
        "with torch.no_grad():\n",
        "    for digit in range(10):\n",
        "        z = torch.randn(1, z_dim).to(device)\n",
        "        label = torch.tensor([digit]).to(device)\n",
        "        generated = G(z, label)\n",
        "\n",
        "        # Save each image individually\n",
        "        save_path = os.path.join(digit_save_dir, f'digit_{digit}.png')\n",
        "        save_image(generated, save_path, normalize=True)\n",
        "        print(f\"Saved digit {digit} to {save_path}\")\n",
        "\n",
        "# Zip the folder containing all digit images\n",
        "zip_path = \"/content/digit_images\"\n",
        "shutil.make_archive(zip_path, 'zip', digit_save_dir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_path + \".zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qY0PE06KOIUz",
        "outputId": "8ae4fcd2-96db-404c-a65a-2b09ac494510"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7f28478c-00fd-47b5-86e6-80767c6d80ce\", \"generated_epoch_20.png\", 5227)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Generator\n",
        "torch.save(G.state_dict(), \"/content/generator.pth\")\n",
        "\n",
        "# Save Discriminator\n",
        "torch.save(D.state_dict(), \"/content/discriminator.pth\")"
      ],
      "metadata": {
        "id": "QIDwsvAXR6qd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download generator\n",
        "files.download(\"/content/generator.pth\")\n",
        "\n",
        "# Download discriminator\n",
        "files.download(\"/content/discriminator.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "E0F_Zh0aSBfB",
        "outputId": "df1a580e-9627-4c85-b7f6-fe15144609d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_237443ba-95aa-42d6-85a9-fcd14b752691\", \"generator.pth\", 3298189)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f8c41c0b-b32a-4f06-b55a-0ac6b99d1ec3\", \"discriminator.pth\", 602194)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(G, \"/content/generator_full.pth\")"
      ],
      "metadata": {
        "id": "AS5_GmLLSPoY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"/content/generator_full.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TBQqWFF_SVf1",
        "outputId": "187fb2b2-9e1d-43bd-8f13-3b81959625ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4fe5cc86-7a73-46ca-acaa-55f3cce7e978\", \"generator_full.pth\", 3301558)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Generator class ===\n",
        "class ConditionalGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, img_channels=1):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim + num_classes, 128, 7, 1, 0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z, labels):\n",
        "        label_embedding = self.label_emb(labels)\n",
        "        x = torch.cat([z, label_embedding], dim=1)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        return self.net(x)\n",
        "\n",
        "# === Load Generator ===\n",
        "z_dim = 100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "G = ConditionalGenerator(z_dim=z_dim, num_classes=10).to(device)\n",
        "G.load_state_dict(torch.load(\"/content/generator.pth\", map_location=device))\n",
        "G.eval()\n",
        "\n",
        "# === Get user input ===\n",
        "digit = int(input(\"Enter a digit (0–9) to generate: \"))\n",
        "if digit < 0 or digit > 9:\n",
        "    raise ValueError(\"Please enter a number between 0 and 9.\")\n",
        "\n",
        "# === Generate ===\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(1, z_dim).to(device)\n",
        "    label = torch.tensor([digit]).to(device)\n",
        "    generated = G(z, label)  # [1, 1, 28, 28]\n",
        "\n",
        "# === Fix the black image: rescale from [-1, 1] to [0, 1] ===\n",
        "generated_rescaled = (generated + 1) / 2  # now values are in [0, 1]\n",
        "\n",
        "# === Display the image ===\n",
        "img = to_pil_image(generated_rescaled.squeeze(0).cpu())  # no need for mode='F' now\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.title(f\"Generated Digit: {digit}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "aFgvZ77mTBq-",
        "outputId": "d9124336-e9d3-413c-973f-2418d1c747dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a digit (0–9) to generate: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}